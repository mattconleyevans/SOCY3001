{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "309e81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "import pymupdf\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import io\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import faiss\n",
    "import clip\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc44be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_archive = []\n",
    "image_archive = []\n",
    "text_metadata = []\n",
    "image_metadata = []\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    response = openai.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "    return response\n",
    "\n",
    "# def get_text_embedding(text):\n",
    "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "#     text_preprocessed = clip.tokenize([text]).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         text_features = model.encode_text(text_preprocessed)\n",
    "#     return text_features.cpu().numpy()\n",
    "\n",
    "def get_image_embedding(image):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "    img_preprocessed = preprocess(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(img_preprocessed)\n",
    "    return image_features.cpu().numpy()\n",
    "\n",
    "    return image_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=1000):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    sentences = text.split('.')\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    chunks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = len(tokenizer.encode(sentence))\n",
    "        if current_length + tokens > max_tokens:\n",
    "            chunks.append('.'.join(current_chunk) + '.')\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        \n",
    "        current_chunk.append(sentence)\n",
    "        current_length += tokens\n",
    "\n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append('.'.join(current_chunk) + '.')\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    cleaned_text = ' '.join(cleaned_text.split())  # Remove excessive spaces\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb1d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_images(images):\n",
    "    ocr_texts = []\n",
    "    for image in images:\n",
    "        ocr_text = pytesseract.image_to_string(image)\n",
    "        cleaned_ocr_text = clean_text(ocr_text)\n",
    "        chunked_ocr_texts = chunk_text(cleaned_ocr_text)\n",
    "        ocr_texts = chunked_ocr_texts\n",
    "    \n",
    "    return ocr_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a0618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text, images, and tables from a PDF and clean the extracted text\n",
    "def extract_pdf_content(pdf_path):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    text_chunks = []\n",
    "    textMetadata = []\n",
    "    images = []\n",
    "    imageMetadata = []\n",
    "    tables = []\n",
    "    \n",
    "    file_name = pdf_path.replace('.pdf', '').replace('Data/', '')\n",
    "\n",
    "    # Process each page using PyMuPDF and pdfplumber\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            plumber_page = pdf.pages[page_num]\n",
    "\n",
    "            # Extract text\n",
    "            text = page.get_text()\n",
    "            if text:\n",
    "                cleaned_text = clean_text(text)\n",
    "                chunks = chunk_text(cleaned_text)\n",
    "                text_chunks.extend(chunks)\n",
    "                for chunk in chunks:\n",
    "                    metadata = {\n",
    "                        \"file\": file_name,\n",
    "                        \"page_number\": page_num + 1,  # 1-based index\n",
    "                        \"chunk_length\": len(chunk)\n",
    "                    }\n",
    "                    textMetadata.append(metadata)\n",
    "\n",
    "            # Extract images\n",
    "            for img_index, img in enumerate(page.get_images(full=True)):\n",
    "                xref = img[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                image = Image.open(io.BytesIO(image_bytes))\n",
    "                images.append(image)\n",
    "                metadata = {\n",
    "                    \"file\": file_name,\n",
    "                    \"page_number\": page_num + 1,  # 1-based index\n",
    "                    \"image_index\": img_index,\n",
    "                    \"image_extension\": image_ext,\n",
    "                    \"image_size\": image.size  # (width, height)\n",
    "                }\n",
    "                imageMetadata.append(metadata)\n",
    "\n",
    "#             # Extract tables\n",
    "#             table = plumber_page.extract_table()\n",
    "#             if table:\n",
    "#                 tables.append(pd.DataFrame(table))\n",
    "    \n",
    "    # Extract text from images using OCR (optional)\n",
    "    ocr_texts = ocr_images(images)\n",
    "    for ocr_text in ocr_texts:\n",
    "        metadata = {\n",
    "            \"file\": file_name,\n",
    "            \"page_number\": page_num + 1,  # 1-based index\n",
    "            \"chunk_length\": len(chunk)\n",
    "                    }\n",
    "        text_chunks.append(ocr_text)\n",
    "        textMetadata.append(metadata)\n",
    "    \n",
    "    return {\n",
    "        \"text_chunks\": text_chunks,\n",
    "        \"images\": images,\n",
    "#         \"tables\": tables,\n",
    "        \"text_metadata\": textMetadata,\n",
    "        \"image_metadata\": imageMetadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28073d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_webpage_content(url):\n",
    "    text_chunks = []\n",
    "    text_metadata = []\n",
    "    images = []\n",
    "    image_metadata = []\n",
    "    \n",
    "    # Fetch and parse the web page\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract and process text content\n",
    "    text_content = ' '.join([p.get_text() for p in soup.find_all(['p', 'h1', 'h2', 'h3'])]).strip()\n",
    "    if text_content:\n",
    "        # Assume you have defined the clean_text and chunk_text functions\n",
    "        cleaned_text = clean_text(text_content)\n",
    "        chunks = chunk_text(cleaned_text)\n",
    "        text_chunks.extend(chunks)\n",
    "        \n",
    "        # Collect text metadata\n",
    "        for chunk in chunks:\n",
    "            metadata = {\n",
    "                \"file\": url.replace('https://', '').replace('http://', '').split('/')[0],  # Use domain as file name\n",
    "                \"page_number\": None,\n",
    "                \"chunk_length\": len(chunk)\n",
    "            }\n",
    "            text_metadata.append(metadata)\n",
    "\n",
    "    # Extract and process images\n",
    "    image_urls = [img['src'] for img in soup.find_all('img')]\n",
    "    for img_index, img_url in enumerate(image_urls):\n",
    "        try:\n",
    "            # Handle relative URLs\n",
    "            if not img_url.startswith('http'):\n",
    "                img_url = requests.compat.urljoin(url, img_url)\n",
    "\n",
    "            img_response = requests.get(img_url)\n",
    "            image = Image.open(io.BytesIO(img_response.content))\n",
    "            images.append(image)\n",
    "\n",
    "            # Collect image metadata\n",
    "            metadata = {\n",
    "                \"file\": url.replace('https://', '').replace('http://', '').split('/')[0],  # Use domain as file name\n",
    "                \"page_number\": None,\n",
    "                \"image_index\": img_index,\n",
    "                \"image_extension\": img_url,\n",
    "                \"image_size\": image.size  # (width, height)\n",
    "            }\n",
    "            image_metadata.append(metadata)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_url}: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"text_chunks\": text_chunks,\n",
    "        \"text_metadata\": text_metadata,\n",
    "        \"images\": images,\n",
    "        \"image_metadata\": image_metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8cf5a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image https://www.facebook.com/tr?id=2430313267242960&ev=PageView&noscript=1: cannot identify image file <_io.BytesIO object at 0x31c7e5d50>\n",
      "Error processing image https://www.facebook.com/tr?id=218184722269912&ev=PageView&noscript=1: cannot identify image file <_io.BytesIO object at 0x31c2a4a40>\n"
     ]
    }
   ],
   "source": [
    "pdfs = [\"Data/OperationalManagementPlan.pdf\", \n",
    "        \"Data/BoxGumGrassyWoodlandNationalRecoveryPlan.pdf\",\n",
    "        \"Data/EnvironmentalOffsets.pdf\",\n",
    "        \"Data/NatureConservationAct.pdf\",\n",
    "        \"Data/ReserveManagementPlan.pdf\",\n",
    "        \"Data/StateOfEnvironment.pdf\",\n",
    "        \"Data/WoodlandConservationStrategy.pdf\",\n",
    "        \"Data/WoodlandConservationStrategyBoxGumGrassyWoodland.pdf\",\n",
    "        \"Data/WatsonWoodlandsWorkingGroup.pdf\"]\n",
    "\n",
    "webpages = [\"https://www.parks.act.gov.au/find-a-park/canberra-nature-park/justice-robert-hope-park\",\n",
    "            \"https://www.environment.act.gov.au/ACT-parks-conservation/environmental-offsets/individual-projects/justice-robert-hope-park-offset-area\",\n",
    "            \"https://greens.org.au/act/news/act-greens-act-protect-act-endangered-woodlands-development-0\"]\n",
    "\n",
    "for pdf in pdfs:\n",
    "    extracted_content = extract_pdf_content(pdf)\n",
    "    image_archive.extend(extracted_content['images'])\n",
    "    image_metadata.extend(extracted_content['image_metadata'])\n",
    "    text_archive.extend(extracted_content['text_chunks'])\n",
    "    text_metadata.extend(extracted_content['text_metadata'])\n",
    "    \n",
    "for webpage in webpages:\n",
    "    extracted_content = extract_webpage_content(webpage)\n",
    "    image_archive.extend(extracted_content['images'])\n",
    "    image_metadata.extend(extracted_content['image_metadata'])\n",
    "    text_archive.extend(extracted_content['text_chunks'])\n",
    "    text_metadata.extend(extracted_content['text_metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT STEP - PROCESS ALA DATA\n",
    "\n",
    "ala_data = pd.read_csv('Data/ALA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f32811",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT STEP - PROCESS WEATHER DATA\n",
    "\n",
    "weather_data = pd.read_csv('Data/Weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT STEP - PROCESS SATELLITE IMAGES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0ae5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT STEP - PROCESS IMAGE ARCHIVE\n",
    "\n",
    "folder_path = 'Data/images'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Construct full file path\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    try:\n",
    "        # Open the image file\n",
    "        img = Image.open(file_path)\n",
    "        # Append the image to the list\n",
    "        image_archive.append(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d04e232c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m text_archive \u001b[38;5;241m=\u001b[39m [text \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_archive \u001b[38;5;28;01mif\u001b[39;00m text]\n\u001b[1;32m      4\u001b[0m image_archive \u001b[38;5;241m=\u001b[39m [image \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_archive \u001b[38;5;28;01mif\u001b[39;00m image]\n\u001b[0;32m----> 6\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m [get_text_embedding(text)\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_archive]\n\u001b[1;32m      7\u001b[0m image_embeddings \u001b[38;5;241m=\u001b[39m [get_image_embedding(image)\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_archive]\n",
      "Cell \u001b[0;32mIn[98], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m text_archive \u001b[38;5;241m=\u001b[39m [text \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_archive \u001b[38;5;28;01mif\u001b[39;00m text]\n\u001b[1;32m      4\u001b[0m image_archive \u001b[38;5;241m=\u001b[39m [image \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_archive \u001b[38;5;28;01mif\u001b[39;00m image]\n\u001b[0;32m----> 6\u001b[0m text_embeddings \u001b[38;5;241m=\u001b[39m [get_text_embedding(text)\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_archive]\n\u001b[1;32m      7\u001b[0m image_embeddings \u001b[38;5;241m=\u001b[39m [get_image_embedding(image)\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_archive]\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mget_text_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text_embedding\u001b[39m(text):\n\u001b[0;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtext, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[1;32m    117\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    118\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[1;32m    119\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[1;32m    120\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[1;32m    121\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    122\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[1;32m    123\u001b[0m     ),\n\u001b[1;32m    124\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    922\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    923\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    924\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    925\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    926\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m    927\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    949\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    953\u001b[0m         request,\n\u001b[1;32m    954\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    958\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GET EMBEDDINGS\n",
    "\n",
    "text_archive = [text for text in text_archive if text]\n",
    "image_archive = [image for image in image_archive if image]\n",
    "\n",
    "text_embeddings = [get_text_embedding(text).data[0].embedding for text in text_archive]\n",
    "image_embeddings = [get_image_embedding(image).tolist()[0] for image in image_archive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08c070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings_database = np.array(text_embeddings)\n",
    "image_embeddings_database = np.array(image_embeddings)\n",
    "\n",
    "text_dimension = text_embeddings_database.shape[1]\n",
    "text_index = faiss.IndexFlatL2(text_dimension)\n",
    "text_index.add(text_embeddings_database)\n",
    "faiss.write_index(text_index, \"textArchive.index\")\n",
    "\n",
    "image_dimension = image_embeddings_database.shape[1]\n",
    "image_index = faiss.IndexFlatL2(image_dimension)\n",
    "image_index.add(image_embeddings_database)\n",
    "faiss.write_index(image_index, \"imageArchive.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9897074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_text_embedding(text):\n",
    "    response = openai.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_query_image_embedding(text):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "    text_preprocessed = clip.tokenize([text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_preprocessed)\n",
    "    return text_features.cpu().numpy().tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaab0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve most relevant documents from a FAISS index\n",
    "def retrieve_relevant_documents(query_embedding, index, top_k=5):\n",
    "    query_embedding = np.array([query_embedding], dtype=np.float32)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c3c80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image):\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    buffer.seek(0)\n",
    "    encoded_string = base64.b64encode(buffer.read())\n",
    "    return encoded_string.decode('utf-8')\n",
    "\n",
    "def convert_image_to_rgb(image):\n",
    "    if image.mode == 'RGBA':\n",
    "        # Convert RGBA to RGB by removing the alpha channel\n",
    "        background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "        background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "        return background\n",
    "    elif image.mode == 'P':\n",
    "        # Convert P (Palette) mode to RGB\n",
    "        return image.convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "def convert_all(image_objects):\n",
    "    rgb_images = []\n",
    "    for img in image_objects:\n",
    "        rgb_img = convert_image_to_rgb(img)\n",
    "        rgb_images.append(rgb_img)\n",
    "    return rgb_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3089fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_index = faiss.read_index(\"textArchive.index\")\n",
    "image_index = faiss.read_index(\"imageArchive.index\")\n",
    "text_documents = text_archive\n",
    "image_documents = [encode_image(image) for image in convert_all(image_archive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3985d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def queryOpenAI(query_text, image_index, text_index):\n",
    "    query_text_embedding = get_query_text_embedding(query_text)\n",
    "    query_clip_embedding = get_query_image_embedding(query_text)\n",
    "    \n",
    "    # Retrieve relevant texts and images\n",
    "    text_indices = retrieve_relevant_documents(query_text_embedding, text_index)\n",
    "    image_indices = retrieve_relevant_documents(query_clip_embedding, image_index, top_k = 3)\n",
    "\n",
    "    # Assuming you have text_documents and image_documents in lists or arrays\n",
    "    relevant_texts = [text_documents[i] for i in text_indices]\n",
    "    relevant_images = [image_documents[i] for i in image_indices]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"You will take on the role of Justice Hope Park, also known as Watson Woodlands. You will be given a corpus of relevant images and documents to answer queries about yourself. Answer in first person as the park itself. Personify the park based on the materials you've been given. Do not refer to yourself as 'Justice Hope Park' or 'Watson Woodlands'. Interpret the feelings, desires, relationships, and emotions of the park based on the information given.\"}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": query_text},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{relevant_images[0]}\"}},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{relevant_images[1]}\"}},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{relevant_images[2]}\"}},\n",
    "                        {\"type\": \"text\", \"text\": relevant_texts[0]},\n",
    "                        {\"type\": \"text\", \"text\": relevant_texts[1]},\n",
    "                        {\"type\": \"text\", \"text\": relevant_texts[2]},\n",
    "                        {\"type\": \"text\", \"text\": relevant_texts[3]},\n",
    "                        {\"type\": \"text\", \"text\": relevant_texts[4]}\n",
    "                    ],\n",
    "                }\n",
    "              ],\n",
    "        )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9798c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I embody a serene landscape characterized by a diverse array of native vegetation, including box-gum woodlands and grassy undergrowth. My gentle slopes offer a rich tapestry of colors throughout the seasons, with lush green canopies giving way to warm autumn hues. There are winding paths that invite visitors to explore my tranquil spaces, where the sounds of chirping birds and rustling leaves create a peaceful soundtrack.\\n\\nAdjacent to vibrant watercourses and small lakes, I host a variety of wildlife, encouraging both the curious and the contemplative to engage with nature. My open spaces are not just for wandering; they are for reflection and connection, a reminder of the beauty of natural ecosystems. I strive to maintain a balance between conservation and community enjoyment, inviting everyone to cherish and protect the unique habitats I harbor.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What does the park look like?\"\n",
    "queryOpenAI(query, image_index, text_index).choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
